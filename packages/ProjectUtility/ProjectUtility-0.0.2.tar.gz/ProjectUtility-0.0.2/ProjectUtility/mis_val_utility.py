# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_mis_val_utility.ipynb.

# %% auto 0
__all__ = ['MissingValuesAnalyzer', 'group_based_minprob_impute']

# %% ../nbs/02_mis_val_utility.ipynb 5
# Standard libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional, Union, Tuple, Any


# Missing value visualization
import missingno as msno

# Handle warnings
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# %% ../nbs/02_mis_val_utility.ipynb 8
class MissingValuesAnalyzer:
    """
    A class for visualizing and analyzing missing data in pandas DataFrames.
    
    Attributes:
    -----------
    df : pandas DataFrame
        Input dataframe to analyze
    """
    
    def __init__(self, df: pd.DataFrame):
        """
        Initialize MissingValuesAnalyzer with a dataframe.
        
        Parameters:
        -----------
        df : pandas DataFrame
            Input dataframe to analyze
        """
        self.df = df
        self.missing_summary = self._generate_missing_summary()
    
    def _generate_missing_summary(self) -> Dict[str, Any]:
        """
        Generate summary statistics about missing values.
        
        Returns:
        --------
        dict
            Dictionary containing summary statistics
        """
        # Overall statistics
        total_cells = self.df.size
        missing_cells = self.df.isna().sum().sum()
        missing_percentage = (missing_cells / total_cells) * 100
        
        # By column
        col_stats = pd.DataFrame({
            'missing_count': self.df.isna().sum(),
            'missing_percentage': (self.df.isna().sum() / len(self.df) * 100)
        }).sort_values('missing_count', ascending=False)
        
        # By row
        row_stats = pd.DataFrame({
            'missing_count': self.df.isna().sum(axis=1),
            'missing_percentage': (self.df.isna().sum(axis=1) / self.df.shape[1] * 100)
        })
        
        # Calculate mean values (for scatter plot)
        try:
            row_stats['log2_mean'] = np.log2(self.df.mean(axis=1, skipna=True))
        except:
            row_stats['log2_mean'] = np.nan
            print("Warning: Could not calculate log2 mean values. Non-numeric data may be present.")
        
        # Value counts of missing counts per row
        missing_counts_dist = self.df.isna().sum(axis=1).value_counts().sort_index()
        
        return {
            'total_cells': total_cells,
            'missing_cells': missing_cells,
            'missing_percentage': missing_percentage,
            'column_stats': col_stats,
            'row_stats': row_stats,
            'missing_counts_dist': missing_counts_dist
        }
    
    def plot_missing_matrix(self, ax=None, **kwargs):
        """
        Plot a matrix visualization of missing values.
        
        Parameters:
        -----------
        ax : matplotlib.axes.Axes, optional
            Axes to plot on
        **kwargs : 
            Additional arguments to pass to msno.matrix
            
        Returns:
        --------
        matplotlib.axes.Axes
            The axes containing the plot
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        # Use missingno to create matrix plot
        msno.matrix(self.df, ax=ax, **kwargs)
        
        # Adjust title and styling
        ax.set_title("Missing Values Matrix", fontsize=14)
        ax.set_xlabel("Features", fontsize=12)
        ax.set_ylabel("Samples", fontsize=12)
        
        return ax
    
    def plot_missing_dendrogram(self, ax=None, orientation='right', **kwargs):
        """
        Plot a dendrogram of missing value correlations.
        
        Parameters:
        -----------
        ax : matplotlib.axes.Axes, optional
            Axes to plot on
        orientation : str
            Orientation of the dendrogram ('top', 'right', 'bottom', or 'left')
        **kwargs : 
            Additional arguments to pass to msno.dendrogram
            
        Returns:
        --------
        matplotlib.axes.Axes
            The axes containing the plot
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        # Use missingno to create dendrogram
        msno.dendrogram(self.df, ax=ax, orientation=orientation, **kwargs)
        
        # Adjust title and styling
        ax.set_title("Missing Values Correlation Dendrogram", fontsize=14)
        
        return ax
    
    def plot_missing_counts_distribution(self, ax=None, **kwargs):
        """
        Plot the distribution of missing value counts per row.
        
        Parameters:
        -----------
        ax : matplotlib.axes.Axes, optional
            Axes to plot on
        **kwargs : 
            Additional arguments to pass to plot
            
        Returns:
        --------
        matplotlib.axes.Axes
            The axes containing the plot
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        # Get the distribution
        dist = self.missing_summary['missing_counts_dist']
        
        # Plot as bar chart
        dist.plot(kind='bar', ax=ax, color='#3498db', **kwargs)
        
        # Adjust title and styling
        ax.set_title("Distribution of Missing Values per Sample", fontsize=14)
        ax.set_xlabel("Number of Missing Values", fontsize=12)
        ax.set_ylabel("Count of Samples", fontsize=12)
        
        # Add counts above bars
        for i, count in enumerate(dist):
            ax.text(i, count + (max(dist) * 0.02), str(count), ha='center')
        
        return ax
    
    def plot_missing_vs_mean(self, ax=None, **kwargs):
        """
        Plot the relationship between missing values and feature means.
        
        Parameters:
        -----------
        ax : matplotlib.axes.Axes, optional
            Axes to plot on
        **kwargs : 
            Additional arguments to pass to scatter
            
        Returns:
        --------
        matplotlib.axes.Axes
            The axes containing the plot
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        # Get the data
        row_stats = self.missing_summary['row_stats']
        
        # Set default scatter point size
        kwargs.setdefault('s', 10)
        kwargs.setdefault('alpha', 0.5)
        
        # Plot scatter
        ax.scatter(
            row_stats['log2_mean'], 
            row_stats['missing_count'],
            color='#e74c3c',
            **kwargs
        )
        
        # Adjust title and styling
        ax.set_title("Missing Values vs. Log2 Mean", fontsize=14)
        ax.set_xlabel("Log2 Mean Value", fontsize=12)
        ax.set_ylabel("Number of Missing Values", fontsize=12)
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def plot_missing_dashboard(self, figsize=(14, 12)):
        """
        Create a comprehensive dashboard of missing value visualizations.
        
        Parameters:
        -----------
        figsize : tuple
            Figure size (width, height) in inches
            
        Returns:
        --------
        tuple
            (figure, axes) - The matplotlib figure and axes objects
        """
        # Create figure and axes
        fig, axes = plt.subplots(2, 2, figsize=figsize)
        fig.suptitle(f"Missing Values Analysis - {self.df.shape[0]} samples Ã— {self.df.shape[1]} features", 
                    fontsize=16, y=0.98)
        
        # Add some space between subplots
        plt.subplots_adjust(wspace=0.3, hspace=0.3)
        
        # 1. Matrix plot (top left)
        self.plot_missing_matrix(ax=axes[0, 0], sparkline=False)
        
        # 2. Dendrogram (top right)
        self.plot_missing_dendrogram(ax=axes[0, 1], orientation='right')
        
        # 3. Missing counts distribution (bottom left)
        self.plot_missing_counts_distribution(ax=axes[1, 0])
        
        # 4. Missing vs mean (bottom right)
        self.plot_missing_vs_mean(ax=axes[1, 1])
        
        # Add overall statistics as text
        stats_text = (
            f"Overall Missing: {self.missing_summary['missing_percentage']:.2f}% "
            f"({self.missing_summary['missing_cells']} of {self.missing_summary['total_cells']} cells)\n"
            f"Samples with no missing data: {(self.missing_summary['row_stats']['missing_count'] == 0).sum()} "
            f"({(self.missing_summary['row_stats']['missing_count'] == 0).sum() / len(self.df) * 100:.1f}%)"
        )
        plt.figtext(0.5, 0.01, stats_text, ha="center", fontsize=12, bbox={"facecolor":"orange", "alpha":0.2, "pad":5})
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        
        return fig, axes, self.missing_summary

# %% ../nbs/02_mis_val_utility.ipynb 17
def group_based_minprob_impute(df, group_vector, quantile=0.0001, sd_factor=0.2, random_state=None):
    """
    Group-based MinProb imputation for proteomics data.
    First computes quantile distribution statistics for each condition group by merging all values
    within the condition. Then imputes missing values only for rows where all values in a particular
    condition are missing by drawing random values from the calculated distribution.
    
    Parameters:
      df (pd.DataFrame): Input DataFrame in log space (rows: proteins, columns: samples)
      group_vector (list): Vector indicating group membership of each column
      quantile (float): Quantile to use as the center for the imputation (default: 0.01)
      sd_factor (float): Factor to multiply the standard deviation for noise level (default: 0.2)
      random_state (int, optional): Random seed for reproducibility
      
    Returns:
      pd.DataFrame: DataFrame with imputed missing values.
    """
    # Set random seed if provided
    if random_state is not None:
        np.random.seed(random_state)
    
    # Verify group_vector length matches df columns
    if len(group_vector) != df.shape[1]:
        raise ValueError(f"Length of group_vector ({len(group_vector)}) must match number of columns in df ({df.shape[1]})")
    
    # Convert group_vector to numpy array for easier manipulation
    group_vector = np.array(group_vector)
    
    # Get unique groups
    unique_groups = np.unique(group_vector)
    
    # Create a copy of the dataframe to avoid modifying the original
    imputed_df = df.copy()
    
    # Step 1: Compute quantile distribution statistics for each condition group
    print("Computing condition statistics:")
    condition_stats = {}
    for group in unique_groups:
        # Get all values from this condition group
        group_cols = np.where(group_vector == group)[0]
        group_data = df.iloc[:, group_cols].values.flatten()
        
        # Remove NaN values
        group_data = group_data[~np.isnan(group_data)]
        
        if len(group_data) > 0:
            # Calculate statistics for this condition
            condition_stats[group] = {
                'low_center': np.quantile(group_data, quantile),
                'noise_sd': sd_factor * np.std(group_data) if len(group_data) > 1 else sd_factor * 0.1
            }
            print(f"  Condition {group}: {len(group_data)} valid values, center={condition_stats[group]['low_center']:.4f}, "
                  f"noise_sd={condition_stats[group]['noise_sd']:.4f}")
        else:
            print(f"  Warning: Condition {group} has no valid data for computing statistics")
    
    # Step 2: Process each row and impute missing values
    print("\nImputing missing values:")
    imputation_count = 0
    
    for i in range(len(imputed_df)):
        row = imputed_df.iloc[i]
        row_imputed = False
        
        # Check each group for this row
        for group in unique_groups:
            # Get column indices for current group
            group_cols = np.where(group_vector == group)[0]
            
            # Get values for this row in the current group
            group_values = row.iloc[group_cols]
            
            # Check if ALL values in this group are NaN for this row
            if group_values.isna().all():
                if group not in condition_stats:
                    print(f"  Cannot impute condition {group} for row {i} (index: {imputed_df.index[i]}) - no statistics available")
                    continue
                    
                # Get the pre-computed statistics for this condition
                low_center = condition_stats[group]['low_center']
                noise_sd = condition_stats[group]['noise_sd']
                
                # Generate random values for imputation
                imputed_values = np.random.normal(
                    loc=low_center, 
                    scale=noise_sd, 
                    size=len(group_cols)
                )
                
                # Clip values to be at most the low center (keeping them as low signals)
                imputed_values = np.minimum(imputed_values, low_center)
                
                # Assign imputed values to the group columns for this row
                for j, col_idx in enumerate(group_cols):
                    imputed_df.iat[i, col_idx] = imputed_values[j]
                
                row_imputed = True
                imputation_count += len(group_cols)
        
        if row_imputed:
            print(f"  Imputed missing values for row {i} (index: {imputed_df.index[i]})")
    
    print(f"\nImputation complete: {imputation_count} values imputed across {len(imputed_df)} rows")
    return imputed_df

