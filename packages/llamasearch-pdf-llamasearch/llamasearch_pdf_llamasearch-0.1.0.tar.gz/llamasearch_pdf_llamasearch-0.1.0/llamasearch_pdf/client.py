"""
Client module for llamasearch-pdf.
"""

class Config:
    """Configuration for the Client."""
    
    def __init__(self, timeout=60, retries=3, verbose=False):
        """
        Initialize a Config instance.
        
        Args:
            timeout (int, optional): Request timeout in seconds. Defaults to 60.
            retries (int, optional): Number of retry attempts. Defaults to 3.
            verbose (bool, optional): Enable verbose logging. Defaults to False.
        """
        self.timeout = timeout
        self.retries = retries
        self.verbose = verbose


class Client:
    """Main client for interacting with the llamasearch-pdf API."""
    
    def __init__(self, api_key=None, base_url=None, config=None):
        """
        Initialize a Client instance.
        
        Args:
            api_key (str, optional): Your API key. Defaults to None.
            base_url (str, optional): Base URL for API requests. Defaults to None.
            config (Config, optional): Configuration options. Defaults to None.
        """
        self.api_key = api_key
        self.base_url = base_url or "https://api.llamasearch.ai/llamasearch-pdf"
        self.config = config or Config()
    
    def process_data(self, data, options=None):
        """
        Process the provided data.
        
        Args:
            data (str): The data to process.
            options (dict, optional): Additional options. Defaults to None.
            
        Returns:
            dict: The processed result.
        """
        if self.config.verbose:
            print(f"Processing data: {data[:50]}...")
        
        # This is a mock implementation
        # In a real project, this would make an API request
        
        # Simulate processing
        result = {
            "status": "success",
            "data": f"Processed: {data}",
            "metadata": {
                "timestamp": "2025-01-01T12:00:00Z",
                "source": "llamasearch-pdf",
                "version": "0.1.0"
            }
        }
        
        if options:
            result["options_used"] = options
        
        return result
    
    def batch_process(self, data_items, options=None):
        """
        Process multiple data items.
        
        Args:
            data_items (list): List of data items to process.
            options (dict, optional): Additional options. Defaults to None.
            
        Returns:
            list: List of processed results.
        """
        if self.config.verbose:
            print(f"Batch processing {len(data_items)} items...")
        
        results = []
        for item in data_items:
            results.append(self.process_data(item, options))
        
        return results
    
    def process_data_async(self, data, options=None, on_progress=None, on_complete=None):
        """
        Process data asynchronously with callbacks.
        
        Args:
            data (str): The data to process.
            options (dict, optional): Additional options. Defaults to None.
            on_progress (callable, optional): Progress callback. Defaults to None.
            on_complete (callable, optional): Completion callback. Defaults to None.
            
        Returns:
            Task: A task representing the async operation.
        """
        # This is a mock implementation
        # In a real project, this would use async functionality
        
        # Simulate progress
        if on_progress:
            on_progress(50)
        
        # Process the data
        result = self.process_data(data, options)
        
        # Call completion callback
        if on_complete:
            on_complete(result)
        
        # Return a simple task object (mock)
        return {"status": "completed", "result": result}
