"""
This type stub file was generated by pyright.
"""

import torch
from typing import Any, Dict, List, Optional, TYPE_CHECKING
from .base import HfQuantizer
from ..modeling_utils import PreTrainedModel
from ..utils import is_torch_available
from ..utils.quantization_config import QuantizationConfigMixin

if TYPE_CHECKING:
    ...
if is_torch_available():
    ...
logger = ...
class HiggsHfQuantizer(HfQuantizer):
    """
    Quantizer of the HIGGS method. Enables the loading of prequantized models and in-flight quantization of full-precision models.
    """
    requires_calibration = ...
    requires_parameters_quantization = ...
    required_packages = ...
    def __init__(self, quantization_config: QuantizationConfigMixin, **kwargs) -> None:
        ...
    
    def validate_environment(self, device_map, **kwargs): # -> None:
        ...
    
    def update_torch_dtype(self, torch_dtype: torch.dtype) -> torch.dtype:
        ...
    
    def create_quantized_param(self, model: PreTrainedModel, param_value: torch.Tensor, param_name: str, target_device: torch.device, state_dict: Dict[str, Any], unexpected_keys: Optional[List[str]] = ...): # -> None:
        ...
    
    def update_missing_keys(self, model, missing_keys: List[str], prefix: str) -> List[str]:
        ...
    
    @property
    def is_trainable(self, model: Optional[PreTrainedModel] = ...): # -> Literal[False]:
        ...
    
    def is_serializable(self, safe_serialization=...): # -> Literal[True]:
        ...
    
    def check_quantized_param(self, model: PreTrainedModel, param_value: torch.Tensor, param_name: str, state_dict: Dict[str, Any], **kwargs) -> bool:
        ...
    


