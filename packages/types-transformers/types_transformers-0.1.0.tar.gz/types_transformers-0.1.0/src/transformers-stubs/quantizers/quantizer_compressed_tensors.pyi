"""
This type stub file was generated by pyright.
"""

import torch
from typing import List
from ..utils import is_torch_available
from ..utils.quantization_config import CompressedTensorsConfig
from .base import HfQuantizer

if is_torch_available():
    ...
logger = ...
class CompressedTensorsHfQuantizer(HfQuantizer):
    """
    Quantizer for the compressed_tensors package.  Loads and restores models to
    quantized state with compressed_tensors
    """
    requires_calibration = ...
    required_packages = ...
    def __init__(self, quantization_config: CompressedTensorsConfig, **kwargs) -> None:
        ...
    
    def update_missing_keys_after_loading(self, model, missing_keys: List[str], prefix: str) -> List[str]:
        """
        Update missing keys after loading the model. This is necessary for compressed tensors
        to load the model correctly. We expect weights to be present in missing keys.
        The weight's are re-constructed by ModelCompressor in _process_model_after_weight_loading

        This function cleans up expected missing keys and returns the remaining missing keys
        """
        ...
    
    def update_unexpected_keys(self, model, unexpected_keys: List[str], prefix: str) -> List[str]:
        """
        Override this method if you want to adjust the `unexpected_keys`.

        Args:
            unexpected_keys (`List[str]`, *optional*):
                The list of unexpected keys in the checkpoint compared to the state dict of the model
        """
        ...
    
    def validate_environment(self, *args, **kwargs): # -> None:
        ...
    
    def update_torch_dtype(self, torch_dtype: torch.dtype) -> torch.dtype:
        ...
    
    @property
    def is_quantized(self): # -> bool:
        ...
    
    @property
    def is_quantization_compressed(self): # -> Literal[False]:
        ...
    
    @property
    def is_sparsification_compressed(self): # -> Literal[False]:
        ...
    
    @property
    def is_trainable(self): # -> Literal[True]:
        ...
    
    def is_qat_trainable(self) -> bool:
        """Loaded Models can carry out quantization aware training"""
        ...
    
    def is_serializable(self, safe_serialization=...) -> bool:
        """Models quantized using compressed tensors can be saved to disk"""
        ...
    


