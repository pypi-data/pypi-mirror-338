<h1 align="center">OpenImageTokenizer üñºÔ∏è‚Üíüî¢</h1>

<div align="center">

**Una interfaz Python elegante para los tokenizadores visuales de SEED-Voken**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-APACHE2.0-green.svg)](LICENSE)

</div>

## üìù Descripci√≥n

OpenImageTokenizer es una biblioteca de Python que proporciona una interfaz simplificada y accesible para los potentes tokenizadores visuales desarrollados por TencentARC en su proyecto [SEED-Voken](https://github.com/TencentARC/SEED-Voken). Este paquete facilita el uso de modelos avanzados como Open-MAGVIT2 e IBQ sin necesidad de configuraciones complejas o entornos de desarrollo especializados.

Similar a c√≥mo los tokenizadores de texto convierten texto en tokens discretos, los tokenizadores visuales convierten im√°genes en representaciones discretas (tokens) que pueden ser utilizadas para diversos fines, desde compresi√≥n hasta generaci√≥n de im√°genes autorregresiva.

<p align="center">
<img src="https://raw.githubusercontent.com/TencentARC/SEED-Voken/main/assets/comparsion.png" width=90%>
<br><small><i>Comparaci√≥n de diferentes tokenizadores visuales (imagen de SEED-Voken)</i></small>
</p>

## ‚ú® Caracter√≠sticas

- **Interfaz simplificada**: API intuitiva para usar tokenizadores visuales sin necesidad de entender su complejidad interna
- **Descarga autom√°tica**: Gesti√≥n transparente de checkpoints desde Hugging Face sin intervenci√≥n manual
- **Configuraciones integradas**: No requiere archivos YAML o JSON externos
- **Visualizaci√≥n de tokens**: Herramientas para visualizar y entender los tokens generados
- **Compatible con m√∫ltiples modelos**: Soporte para diferentes versiones de Open-MAGVIT2 e IBQ
- **Multi-plataforma**: Funciona en CPU y GPU sin configuraciones especiales

## üìä Modelos Soportados

OpenImageTokenizer proporciona acceso a los siguientes modelos avanzados de SEED-Voken:

### Open-MAGVIT2

Tokenizador visual estado del arte con rendimiento superior (`0.39 rFID` para downsampling 8x).

- TencentARC/Open-MAGVIT2-Tokenizer-128-resolution
- TencentARC/Open-MAGVIT2-Tokenizer-256-resolution
- TencentARC/Open-MAGVIT2-Tokenizer-16384-Pretrain
- TencentARC/Open-MAGVIT2-Tokenizer-262144-Pretrain

### IBQ

Tokenizador visual escalable con alta dimensi√≥n de c√≥digo y alta utilizaci√≥n.

- TencentARC/IBQ-Tokenizer-16384
- TencentARC/IBQ-Tokenizer-32768

## üõ†Ô∏è Instalaci√≥n

```bash
pypi no soportado
```

O directamente desde el repositorio:

```bash
git clone https://github.com/F4k3r22/OpenImageTokenizer.git
cd OpenImageTokenizer
pip install -e .
```

## üöÄ Uso R√°pido

### Ejemplo B√°sico

```python
from OpenImageTokenizer import MAGVIT2ImageTokenizer

# Inicializar tokenizador (descarga autom√°tica de checkpoints)
tokenizer = MAGVIT2ImageTokenizer("TencentARC/Open-MAGVIT2-Tokenizer-256-resolution")

# Tokenizar una imagen
encoded = tokenizer.encode("ruta/a/imagen.jpg")
tokens = encoded['indices']

# Reconstruir la imagen desde los tokens
reconstructed = tokenizer.decode(encoded['quant'])

# Visualizar los tokens
tokenizer.visualize_tokens(tokens, save_path="tokens_visualization.png")
```

### Procesamiento Completo

```python
# Codificar, decodificar y visualizar en un solo paso
results = tokenizer.process_image("ruta/a/imagen.jpg", "directorio/salida")

print(f"Imagen original: {results['original']}")
print(f"Imagen reconstruida: {results['reconstructed']}")
print(f"Visualizaci√≥n de tokens: {results['tokens']}")
```

## üîç Aplicaciones

Los tokenizadores visuales tienen m√∫ltiples aplicaciones en visi√≥n por computadora e IA:

- **Generaci√≥n autorregresiva de im√°genes**: Base para modelos tipo GPT pero para im√°genes
- **Modelos multimodales**: Punto de conexi√≥n entre modelos de lenguaje y contenido visual
- **Compresi√≥n de im√°genes**: Representaci√≥n eficiente mediante tokens discretos
- **Edici√≥n sem√°ntica**: Manipulaci√≥n a nivel de tokens para edici√≥n controlada
- **Investigaci√≥n en generaci√≥n visual**: Experimentaci√≥n con diferentes arquitecturas

## üß© Componentes Principales

- **MAGVIT2ImageTokenizer**: Clase principal para tokenizaci√≥n con Open-MAGVIT2
- **hf_utils**: M√≥dulo para gestionar la descarga de modelos desde Hugging Face
- **configs**: Configuraciones integradas para los diferentes modelos
- **visualize_tokens**: Utilidades para visualizar y comprender los tokens generados

## üìë Ejemplo de Script Completo

```python
import os
from OpenImageTokenizer import MAGVIT2ImageTokenizer

# Inicializar tokenizador
tokenizer = MAGVIT2ImageTokenizer("TencentARC/Open-MAGVIT2-Tokenizer-256-resolution")

# Cargar el modelo
tokenizer.load_model()

# Procesar imagen (codificar, visualizar, reconstruir)
image_path = "mi_imagen.jpg"
output_dir = "resultados"

results = tokenizer.process_image(image_path, output_dir)

# Mostrar informaci√≥n sobre los tokens
token_shape = results["token_shape"]
print(f"Forma de los tokens: {token_shape}")
print(f"Total de tokens en la imagen: {token_shape[0] * token_shape[1]}")

print("Archivos generados:")
print(f"  Original: {results['original']}")
print(f"  Reconstruido: {results['reconstructed']}")
print(f"  Visualizaci√≥n de tokens: {results['tokens']}")
```

## üìö Citas

Si utilizas OpenImageTokenizer en tu investigaci√≥n, considera citar los trabajos originales:

Para Open-MAGVIT2:

```bibtex
@article{luo2024open,
  title={Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation},
  author={Luo, Zhuoyan and Shi, Fengyuan and Ge, Yixiao and Yang, Yujiu and Wang, Limin and Shan, Ying},
  journal={arXiv preprint arXiv:2409.04410},
  year={2024}
}
```

Para IBQ:

```bibtex
@article{shi2024taming,
  title={Taming Scalable Visual Tokenizer for Autoregressive Image Generation},
  author={Shi, Fengyuan and Luo, Zhuoyan and Ge, Yixiao and Yang, Yujiu and Shan, Ying and Wang, Limin},
  journal={arXiv preprint arXiv:2412.02692},
  year={2024}
}
```

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Para contribuir:

1. Haz un fork del repositorio
2. Crea una nueva rama (`git checkout -b feature/nueva-funcionalidad`)
3. Haz tus cambios y commitealos (`git commit -m 'A√±ade nueva funcionalidad'`)
4. Haz push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° licenciado bajo la licencia APACHE 2.0 - consulta el archivo [LICENSE](LICENSE) para m√°s detalles.

## ‚ù§Ô∏è Agradecimientos

- [TencentARC](https://github.com/TencentARC) por desarrollar [SEED-Voken](https://github.com/TencentARC/SEED-Voken) y los tokenizadores Open-MAGVIT2 e IBQ
- [Hugging Face](https://huggingface.co) por alojar los modelos preentrenados
- Los equipos detr√°s de [VQGAN](https://github.com/CompVis/taming-transformers), [MAGVIT](https://github.com/google-research/magvit), [LlamaGen](https://github.com/FoundationVision/LlamaGen),[RQVAE](https://github.com/kakaobrain/rq-vae-transformer) y [VideoGPT](https://github.com/wilson1yan/VideoGPT), [OmniTokenizer](https://github.com/FoundationVision/OmniTokenizer).
