# llamamlx-embeddings Documentation

Welcome to the documentation for `llamamlx-embeddings`, a high-performance embedding library optimized for Apple Silicon using the MLX framework.

## Overview

This library provides a unified interface for generating text embeddings using Apple's MLX framework. It supports various models, efficient batch processing, quantization, seamless integration with vector databases, and easy deployment as a FastAPI service.

## Features

- 🚀 **MLX Optimizations**: Leverage Apple Silicon's full potential
- 🧩 **Multiple Model Types**: Dense, sparse, and late interaction models
- 💻 **Cross-Platform**: ONNX fallback for non-Apple hardware
- 🔍 **Vector DB Integration**: Easy integration with Qdrant and Pinecone
- 🌐 **FastAPI Server**: Ready-to-use REST API
- 📦 **Batch Processing**: Efficient handling of large datasets
- 🔧 **Quantization**: Reduce memory footprint and improve speed

## Documentation Contents

- [Installation](installation.md)
- [Quickstart](quickstart.md)
- [API Reference](api_reference.md)
- [Examples](examples.md)
- [Benchmarks](benchmarks.md)
- [Contributing](contributing.md) 