# llamamlx-embeddings Documentation

Welcome to the documentation for `llamamlx-embeddings`, a high-performance embedding library optimized for Apple Silicon using the MLX framework.

## Overview

This library provides a unified interface for generating text embeddings using Apple's MLX framework. It supports various models, efficient batch processing, quantization, seamless integration with vector databases, and easy deployment as a FastAPI service.

## Features

- ğŸš€ **MLX Optimizations**: Leverage Apple Silicon's full potential
- ğŸ§© **Multiple Model Types**: Dense, sparse, and late interaction models
- ğŸ’» **Cross-Platform**: ONNX fallback for non-Apple hardware
- ğŸ” **Vector DB Integration**: Easy integration with Qdrant and Pinecone
- ğŸŒ **FastAPI Server**: Ready-to-use REST API
- ğŸ“¦ **Batch Processing**: Efficient handling of large datasets
- ğŸ”§ **Quantization**: Reduce memory footprint and improve speed

## Documentation Contents

- [Installation](installation.md)
- [Quickstart](quickstart.md)
- [API Reference](api_reference.md)
- [Examples](examples.md)
- [Benchmarks](benchmarks.md)
- [Contributing](contributing.md) 