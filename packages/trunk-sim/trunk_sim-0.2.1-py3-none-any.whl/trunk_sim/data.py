import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from typing import List, Tuple, Optional, Union


def get_column_names(
        num_segments: int, states: str, links: List[int]
    )-> Tuple[List[str], List[str], List[str]]:
    """
    Get column names for states, new states, and control inputs.
    """

    if states == "pos":
        state_cols = [
            f"{axis}{link}" for link in links for axis in ["x", "y", "z"]
        ]
        state_new_cols = [
            f"{axis}{link}_new" for link in links for axis in ["x", "y", "z"]
        ]
    elif states == "vel":
        state_cols = [
            f"{axis}{link}" for link in links for axis in ["vx", "vy", "vz"]
        ]
        state_new_cols = [
            f"{axis}{link}_new" for link in links for axis in ["vx", "vy", "vz"]
        ]
    elif states == "pos_vel":
        state_cols = [
            f"{axis}{link}"
            for link in links
            for axis in ["x", "y", "z", "vx", "vy", "vz"]
        ]
        state_new_cols = [
            f"{axis}{link}_new"
            for link in links
            for axis in ["x", "y", "z", "vx", "vy", "vz"]
        ]
    else:
        raise ValueError(f"Invalid states specification: {states}")

    # All control inputs are saved
    control_cols = [
        f"u{axis}{segment}"
        for segment in range(1, num_segments + 1)
        for axis in ["x", "y"]
    ]

    return state_cols, state_new_cols, control_cols


class TrunkData:
    """
    Trunk data class to handle data generated by the Trunk simulator.

    Stores simulation data with time, states, and inputs in a pandas DataFrame.
    Provides functionality to save as CSV and convert to PyTorch dataset.
    """

    def __init__(
        self,
        num_links_per_segment: int,
        num_segments: int,
        states: str = "pos",
        segments: Optional[Union[List, str]] = None,
        links: Optional[Union[List, str]] = None,
    ):
        """
        Initialize a TrunkData object.

        Args:
            num_links_per_segment: number of links in each segment
            num_segments: number of segments in the system
            states: states to be saved ("pos", "vel", "pos_vel")
            segments: segments to be included in the dataset, possibilities are "all", "tip" or a list of segment indices
            links: links to be included in the dataset, possibilities are "all" or a list of link indices. Segments and links cannot be specified at the same time.
        """
        num_links = num_links_per_segment * num_segments

        if segments is not None and links is not None:
            raise ValueError("Cannot specify both segments and links.")

        if links is not None:
            if links == "all":
                links = list(range(1, num_links + 1))
        else:
            if segments is None or segments == "tip":
                links = [num_links]
            elif segments == "all":
                links = list(
                    range(num_links_per_segment, num_links + 1, num_links_per_segment)
                )
            else:
                links = [num_links_per_segment * segment for segment in segments]

        self.states = states
        self.links = links
        self.num_links = num_links
        self.num_segments = num_segments
        self.link_idx = [link - 1 for link in links]

        # Column name patterns
        self.time_col = "t"

        self.state_cols, self.state_new_cols, self.control_cols = get_column_names(
            num_segments, states, links
        )
        
        # Keep track of the trajectory ID
        self.traj_ID_col = "traj_ID"
        
        self.state_dim = len(self.state_cols)
        self.control_dim = len(self.control_cols)

        # Initialize an empty DataFrame
        self.dataframe = pd.DataFrame()

    def add_data(
        self, t: float, x: np.ndarray, u: np.ndarray, x_new: np.ndarray, traj_ID: int = 0
    ) -> None:
        """
        Add a single data point to the dataset.

        Args:
            t: Time value
            x: State vector of shape (num_links, 6)
            u: Input vector of shape (num_links, 2)
            x_new: Next state vector of shape (num_links, 6)
        """

        # Check dimensions
        assert x.shape == (
            self.num_links,
            6,
        ), f"Expected state shape {(self.num_links, 6)}, got {x.shape}"
        assert u.shape == (
            self.num_segments,
            2,
        ), f"Expected input shape {(self.num_segments, 2)}, got {u.shape}"
        assert x_new.shape == (
            self.num_links,
            6,
        ), f"Expected next state shape {(self.num_links, 6)}, got {x_new.shape}"

        # Subselect the desired states
        if self.states == "pos":
            x = x[:, :3]
            x_new = x_new[:, :3]
        elif self.states == "vel":
            x = x[:, 3:]
            x_new = x_new[:, 3:]
        elif self.states == "pos_vel":
            pass

        # Subselect the desired links
        x = x[self.link_idx].flatten()
        u = u.flatten()  # all control inputs are saved
        x_new = x_new[self.link_idx].flatten()

        # Create a new row
        row_data = {self.time_col: t}

        # Add state and input data
        row_data.update(dict(zip(self.state_cols, x)))
        row_data.update(dict(zip(self.control_cols, u)))
        row_data.update(dict(zip(self.state_new_cols, x_new)))

        # Add trajectory ID
        row_data[self.traj_ID_col] = traj_ID

        # Append the new row
        new_row = pd.DataFrame([row_data])
        self.dataframe = pd.concat([self.dataframe, new_row], ignore_index=True)

    def add_batch_data(
        self,
        t_batch: np.ndarray,
        x_batch: np.ndarray,
        u_batch: np.ndarray,
        x_new_batch: np.ndarray,
        traj_ID: int = 0,
    ) -> None:
        """
        Add a batch of data points to the dataset.

        Args:
            t_batch: Array of time values of shape (batch_size,)
            x_batch: Array of state vectors of shape (batch_size, num_links, 6 * num_links)
            u_batch: Array of input vectors of shape (batch_size, num_links, 2 * num_links)
            x_new_batch: Array of next state vectors of shape (batch_size, num_links, 6 * num_links)
        """
        # Expected shapes
        batch_size = len(t_batch)
        expected_x_shape = (batch_size, self.num_links, 6)
        expected_u_shape = (batch_size, self.num_links, 2)
        expected_x_new_shape = (batch_size, self.num_links, 6)

        # Check dimensions
        assert (
            x_batch.shape == expected_x_shape
        ), f"Expected x_batch shape {expected_x_shape}, got {x_batch.shape}"
        assert (
            u_batch.shape == expected_u_shape
        ), f"Expected u_batch shape {expected_u_shape}, got {u_batch.shape}"
        assert (
            x_new_batch.shape == expected_x_new_shape
        ), f"Expected x_new_batch shape {expected_x_new_shape}, got {x_new_batch.shape}"

        # Subselect the desired states
        if self.states == "pos":
            x_batch = x_batch[:, :, :3]
            x_new_batch = x_new_batch[:, :, :3]
        elif self.states == "vel":
            x_batch = x_batch[:, :, 3:]
            x_new_batch = x_new_batch[:, :, 3:]

        # Subselect the desired links
        x_batch = x_batch[:, self.link_idx].reshape(batch_size, -1)
        u_batch = u_batch.reshape(batch_size, -1)  # all control inputs are saved
        x_new_batch = x_new_batch[:, self.link_idx].reshape(batch_size, -1)

        # Create batch data
        batch_data = {self.time_col: t_batch}

        # Add data
        for i, col in enumerate(self.state_cols):
            batch_data[col] = x_batch[:, i]
        for i, col in enumerate(self.control_cols):
            batch_data[col] = u_batch[:, i]
        for i, col in enumerate(self.state_new_cols):
            batch_data[col] = x_new_batch[:, i]
        
        # Add trajectory ID
        batch_data[self.traj_ID_col] = np.full(batch_size, traj_ID)

        # Create and append the new batch
        batch_df = pd.DataFrame(batch_data)
        self.dataframe = pd.concat([self.dataframe, batch_df], ignore_index=True)

    def save_to_csv(self, filename: str) -> None:
        """
        Save the data to a CSV file.

        Args:
            filename: Path to the CSV file to save
        """
        self.dataframe.to_csv(filename, index=False)

    def load_from_csv(self, filename: str) -> None:
        """
        Load data from a CSV file.

        Args:
            filename: Path to the CSV file to load
        """
        self.dataframe = pd.read_csv(filename, index_col=False)

        # Infer column types
        cols = list(self.dataframe.columns)
        if "t" in cols:
            self.time_col = "t"
            cols.remove("t")
        if "traj_ID" in cols:
            self.traj_ID_col = "traj_ID"
            cols.remove("traj_ID")

        # Identify control columns first (assume they start with 'u')
        self.control_cols = [col for col in cols if col.startswith("u")]

        # Separate state and state_new columns (all non-control, non-time columns)
        remaining_cols = [col for col in cols if col not in self.control_cols]

        self.state_cols = [col for col in remaining_cols if not col.endswith("_new")]
        self.state_new_cols = [col for col in remaining_cols if col.endswith("_new")]

        self.state_dim = len(self.state_cols)
        self.control_dim = len(self.control_cols)

    def convert_to_torch_dataset(
        self,
        input_cols: Optional[List[str]] = None,
        output_cols: Optional[List[str]] = None,
    ) -> "TrunkTorchDataset":
        """
        Convert to a PyTorch Dataset.

        Args:
            input_cols: List of column names to use as inputs
            output_cols: List of column names to use as outputs

        Returns:
            A TrunkTorchDataset instance
        """
        if input_cols is None:
            input_cols = self.state_cols + self.control_cols
        if output_cols is None:
            output_cols = self.state_new_cols

        return TrunkTorchDataset(self.dataframe, input_cols, output_cols)
    
    def convert_to_arrays(
        self
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        Convert the data to numpy arrays, split by trajectory ID.
        # TODO: add padding in case of different trajectory lengths

        Returns:
            Tuple of (time_array, state_array, control_array, state_new_array)
        """
        # Get unique trajectory IDs
        traj_IDs = self.dataframe[self.traj_ID_col].unique()

        # Initialize arrays
        time_array = []
        state_array = []
        control_array = []
        state_new_array = []

        # Iterate over trajectories
        for traj_ID in traj_IDs:
            traj_data = self.dataframe[self.dataframe[self.traj_ID_col] == traj_ID]
            time_array.append(traj_data[self.time_col].values)
            state_array.append(traj_data[self.state_cols].values.T)
            control_array.append(traj_data[self.control_cols].values.T)
            state_new_array.append(traj_data[self.state_new_cols].values.T)
        
        time_array = np.array(time_array)  # shape: (num_trajectories, num_timesteps)
        state_array = np.array(state_array)  # shape: (num_trajectories, state_dim, num_timesteps)
        control_array = np.array(control_array)  # shape: (num_trajectories, control_dim, num_timesteps)
        state_new_array = np.array(state_new_array)  # shape: (num_trajectories, state_dim, num_timesteps)

        return time_array, state_array, control_array, state_new_array

    def get_data_at_time(self, t: float) -> np.ndarray:
        """
        Get the single row of data at a specific time.

        Args:
            t: Time value

        Returns:
            Vector with states, control and new states at the given time
        """
        # Find the closest time
        closest_idx = (self.dataframe[self.time_col] - t).abs().idxmin()
        return self.dataframe.loc[closest_idx, :].values

    def __len__(self) -> int:
        """Return the number of data points."""
        return len(self.dataframe)

    def __getitem__(self, idx):
        """Allow indexing the data directly."""
        return self.dataframe.iloc[idx]


class TrunkTorchDataset(Dataset):
    """PyTorch Dataset wrapper for TrunkData."""

    def __init__(
        self, csv_file: Optional[str] = None, dataframe: Optional[pd.DataFrame] = None
    ):
        """
        Initialize a PyTorch dataset from a pandas DataFrame.

        Args:
            dataframe: Source DataFrame
            input_cols: Column names to use as inputs
            output_cols: Column names to use as outputs
        """
        if dataframe and csv_file:
            raise ValueError("Cannot provide both a DataFrame and a CSV file.")
        
        if dataframe:
            self.dataframe = dataframe
        elif csv_file:
            self.dataframe = pd.read_csv(csv_file)
        else:
            raise ValueError("Must provide either a DataFrame or a CSV file.")
        
        self.time_col = "t"

        #TODO: Currently infering from dataframe, should be passed as argument or metadata file.
        self.num_links = len([key for key in self.dataframe.keys() if key.startswith("x") and not key.endswith("_new")])
        self.num_segments = len([key for key in self.dataframe.keys() if key.startswith("ux")])

        self.state_cols, self.state_new_cols, self.control_cols = get_column_names(
            self.num_segments, "pos_vel", list(range(1, self.num_links + 1))
        )

    def __len__(self) -> int:
        """Return the number of data points."""
        return len(self.dataframe)

    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Get a single data point.

        Args:
            idx: Index of the data point

        Returns:
            Tuple of (input_tensor, output_tensor)
        """
        if isinstance(idx, torch.Tensor):
            idx = idx.item()

        # Get input and output values
        t = self.dataframe.iloc[idx][self.time_col]
        states = self.dataframe.iloc[idx][self.state_cols].values
        controls = self.dataframe.iloc[idx][self.control_cols].values
        next_states = self.dataframe.iloc[idx][self.state_new_cols].values

        # Convert to PyTorch tensors
        t = torch.tensor(t, dtype=torch.float32)
        x = torch.tensor(states, dtype=torch.float32).reshape(self.num_links, -1)
        u = torch.tensor(controls, dtype=torch.float32)
        x_new = torch.tensor(next_states, dtype=torch.float32).reshape(self.num_links, -1)

        return {"t": t, "x": x, "u": u, "x_new": x_new}
