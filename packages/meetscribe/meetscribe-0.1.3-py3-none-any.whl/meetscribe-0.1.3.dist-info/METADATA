Metadata-Version: 2.2
Name: meetscribe
Version: 0.1.3
Summary: An intelligent audio-to-transcript chatbot powered by Whisper, PyAnnote, FAISS, and LLMs.
Home-page: https://github.com/jagadale1234/meetscribe
Author: Anish Bipin Jagadale
Author-email: jagdaleanish@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Classifier: License :: OSI Approved :: MIT License
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENCE
Requires-Dist: streamlit
Requires-Dist: openai-whisper
Requires-Dist: torch
Requires-Dist: torchaudio
Requires-Dist: pyannote.audio
Requires-Dist: faiss-cpu
Requires-Dist: langchain
Requires-Dist: langchain-community
Requires-Dist: langchain-openai
Requires-Dist: transformers[torch]
Requires-Dist: sentence-transformers
Requires-Dist: llama-index
Requires-Dist: numpy<2.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# MeetScribe

**MeetScribe** is an intelligent AI-powered tool that converts spoken meeting audio into accurate, speaker-labeled transcripts and allows users to chat with those transcripts using powerful LLMs like GPT-4o.

Powered by OpenAI Whisper, PyAnnote for speaker diarization, and LangChain RAG pipelines.

---

## Features

- 🎙️ **Speaker Diarization** using [PyAnnote](https://github.com/pyannote/pyannote-audio)
- ✍️ **Transcription** using OpenAI's [Whisper](https://github.com/openai/whisper)
- 🧠 **Question Answering** using GPT-4o (or any OpenAI model)
- 🔍 **Customizable Embeddings** – Use HuggingFace or OpenAI Embeddings
- 📜 **Chat History** – Multi-turn conversation memory
- 🖥️ **Streamlit UI** – Easy-to-use local or web-based interface

---

## Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/jagadale1234/meetscribe.git
cd meetscribe
pip install -e .
```
## Requirements
- Hugging Face token (for PyAnnote)

- OpenAI API key (for embeddings + LLM)

## Usage (CLI)

```bash
meetscribe \
  --audio path/to/meeting.wav \
  --openai-key sk-xxx \
  --hf-token hf_yyy
```

## Usage (scripts and notebooks)
```python
from meetscribe import process_audio, ask_question

transcript, qa_chain = process_audio(
    wav_path="meeting.wav",
    openai_key="sk-xxx",
    hf_token="hf-yyy",
    embedding_model="OpenAI"
)

print(transcript)

answer = ask_question(qa_chain, "What was the deadline for the new design?")
print("Answer:", answer)
```


