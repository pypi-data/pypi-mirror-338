ENV:
  BACKEND: nccl
  SEED: 166666
SOLVER:
  NAME: LatentDiffusionSolver
  MAX_STEPS: 100000
  USE_AMP: True
  DTYPE: bfloat16
  USE_FAIRSCALE: False
  USE_FSDP: True
  LOAD_MODEL_ONLY: False
  ENABLE_GRADSCALER: False
  USE_SCALER: False
  RESUME_FROM:
  WORK_DIR: ./cache/save_data/dit_flux_dev_1024_lora
  LOG_FILE: std_log.txt
  EVAL_INTERVAL: 100
  LOG_TRAIN_NUM: 16
  FSDP_REDUCE_DTYPE: float32
  FSDP_BUFFER_DTYPE: float32
  FSDP_SHARD_MODULES: [ 'model', 'cond_stage_model.t5_model' ] #
  SAVE_MODULES: [ 'model'] #
  TRAIN_MODULES: ['model']
  #
  FILE_SYSTEM:
    NAME: "ModelscopeFs"
    TEMP_DIR: "./cache/cache_data"
  #
  FREEZE:
  TUNER:
    - NAME: SwiftLoRA
      R: 4
      LORA_ALPHA: 4
      LORA_DROPOUT: 0.0
      BIAS: "none"
      TARGET_MODULES: "(model.double_blocks.*(.qkv|.proj|.img_mod.lin|.txt_mod.lin))|(model.single_blocks.*(.linear1|.linear2|.modulation.lin))$"
  ##
  MODEL:
    NAME: LatentDiffusionFlux
    PARAMETERIZATION: rf
    TIMESTEPS: 1000
    MIN_SNR_GAMMA:
    ZERO_TERMINAL_SNR: False
    PRETRAINED_MODEL:
    IGNORE_KEYS: [ ]
    DEFAULT_N_PROMPT:
    USE_EMA: False
    EVAL_EMA: False
    DIFFUSION:
      NAME: DiffusionFluxRF
      PREDICTION_TYPE: raw
      NOISE_SCHEDULER:
        NAME: FlowMatchSigmaScheduler
        WEIGHTING_SCHEME: logit_normal
        SHIFT: 3.0
        LOGIT_MEAN: 0.0
        LOGIT_STD: 1.0
        MODE_SCALE: 1.29
      SAMPLER_SCHEDULER:
        NAME: FlowMatchFluxShiftScheduler
        SHIFT: False
        SIGMOID_SCALE: 1
        BASE_SHIFT: 0.5
        MAX_SHIFT: 1.15
        #
    DIFFUSION_MODEL:
      NAME: Flux
      PRETRAINED_MODEL: ms://AI-ModelScope/FLUX.1-dev@flux1-dev.safetensors
      IN_CHANNELS: 64
      HIDDEN_SIZE: 3072
      NUM_HEADS: 24
      AXES_DIM: [ 16, 56, 56 ]
      THETA: 10000
      VEC_IN_DIM: 768
      GUIDANCE_EMBED: True
      CONTEXT_IN_DIM: 4096
      MLP_RATIO: 4.0
      QKV_BIAS: True
      DEPTH: 19
      DEPTH_SINGLE_BLOCKS: 38
      USE_GRAD_CHECKPOINT: True

    #
    FIRST_STAGE_MODEL:
      NAME: AutoencoderKLFlux
      EMBED_DIM: 16
      PRETRAINED_MODEL: ms://AI-ModelScope/FLUX.1-dev@ae.safetensors
      IGNORE_KEYS: [ ]
      BATCH_SIZE: 8
      USE_CONV: False
      SCALE_FACTOR: 0.3611
      SHIFT_FACTOR: 0.1159
      #
      ENCODER:
        NAME: Encoder
        USE_CHECKPOINT: True
        CH: 128
        OUT_CH: 3
        NUM_RES_BLOCKS: 2
        IN_CHANNELS: 3
        ATTN_RESOLUTIONS: [ ]
        CH_MULT: [ 1, 2, 4, 4 ]
        Z_CHANNELS: 16
        DOUBLE_Z: True
        DROPOUT: 0.0
        RESAMP_WITH_CONV: True
      #
      DECODER:
        NAME: Decoder
        USE_CHECKPOINT: True
        CH: 128
        OUT_CH: 3
        NUM_RES_BLOCKS: 2
        IN_CHANNELS: 3
        ATTN_RESOLUTIONS: [ ]
        CH_MULT: [ 1, 2, 4, 4 ]
        Z_CHANNELS: 16
        DROPOUT: 0.0
        RESAMP_WITH_CONV: True
        GIVE_PRE_END: False
        TANH_OUT: False
    #
    COND_STAGE_MODEL:
      NAME: T5PlusClipFluxEmbedder
      T5_MODEL:
        NAME: HFEmbedder
        HF_MODEL_CLS: T5EncoderModel
        MODEL_PATH: ms://AI-ModelScope/FLUX.1-dev@text_encoder_2/
        HF_TOKENIZER_CLS: T5Tokenizer
        TOKENIZER_PATH: ms://AI-ModelScope/FLUX.1-dev@tokenizer_2/
        MAX_LENGTH: 512
        OUTPUT_KEY: last_hidden_state
        D_TYPE: bfloat16
        BATCH_INFER: False
        CLEAN: whitespace
      CLIP_MODEL:
        NAME: HFEmbedder
        HF_MODEL_CLS: CLIPTextModel
        MODEL_PATH: ms://AI-ModelScope/FLUX.1-dev@text_encoder/
        HF_TOKENIZER_CLS: CLIPTokenizer
        TOKENIZER_PATH: ms://AI-ModelScope/FLUX.1-dev@tokenizer/
        MAX_LENGTH: 77
        OUTPUT_KEY: pooler_output
        D_TYPE: bfloat16
        BATCH_INFER: True
        CLEAN: whitespace
        USE_GRAD_CHECKPOINT: True
  #
  SAMPLE_ARGS:
    SAMPLE_STEPS: 50
    SAMPLER: flow_euler
    SEED: 2024
    IMAGE_SIZE: [ 1024, 1024 ]
    GUIDE_SCALE: 3.5
  #
  OPTIMIZER:
    NAME: AdamW
    LEARNING_RATE: 4e-4
    BETAS: [ 0.9, 0.999 ]
    EPS: 1e-8
    WEIGHT_DECAY: 1e-2
    AMSGRAD: False
  #
  TRAIN_DATA:
    NAME: ImageTextPairMSDataset
    MODE: train
    MS_DATASET_NAME: style_custom_dataset
    MS_DATASET_NAMESPACE: damo
    MS_DATASET_SUBNAME: 3D
    PROMPT_PREFIX: ""
    MS_DATASET_SPLIT: train
    MS_REMAP_KEYS: { 'Image:FILE': 'Target:FILE' }
    REPLACE_STYLE: False
    PIN_MEMORY: True
    BATCH_SIZE: 1
    NUM_WORKERS: 4
    SAMPLER:
      NAME: LoopSampler
    TRANSFORMS:
      - NAME: LoadImageFromFile
        RGB_ORDER: RGB
        BACKEND: pillow
      - NAME: FlexibleResize
        INTERPOLATION: bilinear
        SIZE: [ 1024, 1024 ]
        INPUT_KEY: [ 'img' ]
        OUTPUT_KEY: [ 'img' ]
        BACKEND: pillow
      - NAME: FlexibleCenterCrop
        SIZE: [ 1024, 1024 ]
        INPUT_KEY: [ 'img' ]
        OUTPUT_KEY: [ 'img' ]
        BACKEND: pillow
      - NAME: ImageToTensor
        INPUT_KEY: [ 'img' ]
        OUTPUT_KEY: [ 'img' ]
        BACKEND: pillow
      - NAME: Normalize
        MEAN: [ 0.5,  0.5,  0.5 ]
        STD: [ 0.5,  0.5,  0.5 ]
        INPUT_KEY: [ 'img' ]
        OUTPUT_KEY: [ 'image' ]
        BACKEND: torchvision
      - NAME: Select
        KEYS: [ 'image', 'prompt' ]
        META_KEYS: [ 'data_key' ]
  #
  EVAL_DATA:
    NAME: Text2ImageDataset
    MODE: eval
    PROMPT_FILE:
    PROMPT_DATA: [ "a boy wearing a jacket", "a dog running on the lawn" ]
    IMAGE_SIZE: [ 1024, 1024 ]
    FIELDS: [ "prompt" ]
    DELIMITER: '#;#'
    PROMPT_PREFIX: ''
    PIN_MEMORY: True
    BATCH_SIZE: 2
    NUM_WORKERS: 4
    TRANSFORMS:
      - NAME: Select
        KEYS: [ 'index', 'prompt' ]
        META_KEYS: [ 'image_size' ]
  #
  TRAIN_HOOKS:
    - NAME: ProbeDataHook
      PROB_INTERVAL: 100
      PRIORITY: 0
    - NAME: BackwardHook
#      GRADIENT_CLIP: 1.0
      PRIORITY: 10
    - NAME: LogHook
      LOG_INTERVAL: 10
    -
      NAME: TensorboardLogHook
    -
      NAME: CheckpointHook
      INTERVAL: 10000
      PRIORITY: 200
      SAVE_LAST: True
      SAVE_NAME_PREFIX: 'step'
      DISABLE_SNAPSHOT: True
  EVAL_HOOKS:
    - NAME: ProbeDataHook
      PROB_INTERVAL: 100
      PRIORITY: 0