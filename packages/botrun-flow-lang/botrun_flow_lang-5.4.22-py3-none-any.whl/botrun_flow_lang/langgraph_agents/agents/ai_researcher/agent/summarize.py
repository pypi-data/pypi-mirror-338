"""
The summarize node is responsible for summarizing the information.
"""

from copy import deepcopy
import json
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig
from langchain.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from botrun_flow_lang.langgraph_agents.agents.ai_researcher.agent.model import get_model
from botrun_flow_lang.langgraph_agents.agents.ai_researcher.agent.state import (
    AgentState,
)

# from copilotkit.langchain import copilotkit_customize_config
from pydantic import BaseModel, Field
from datetime import datetime

from botrun_flow_lang.langgraph_agents.agents.search_agent_graph import format_dates


class Reference(BaseModel):
    """Model for a reference"""

    title: str = Field(description="The title of the reference.")
    url: str = Field(description="The url of the reference.")


class SummarizeInput(BaseModel):
    """Input for the summarize tool"""

    markdown: str = Field(
        description="""
                          The markdown formatted summary of the final result.
                          If you add any headings, make sure to start at the top level (#).
                          Use actual newline characters (\n) instead of escaped newlines (\\n).
                          """
    )
    references: list[Reference] = Field(description="A list of references.")


@tool(args_schema=SummarizeInput)
def SummarizeTool(
    summary: str, references: list[Reference]
):  # pylint: disable=invalid-name,unused-argument
    """
    Summarize the final result. Make sure that the summary is complete and
    includes all relevant information and reference links.
    """


async def summarize_node(state: AgentState, config: RunnableConfig):
    """
    The summarize node is responsible for summarizing the information.
    """

    # config = copilotkit_customize_config(
    #     config,
    #     emit_intermediate_state=[
    #         {
    #             "state_key": "answer",
    #             "tool": "SummarizeTool",
    #         }
    #     ],
    # )

    steps = deepcopy(state["steps"])
    for step in steps:
        step["search_result"] = None
    now = datetime.now()
    dates = format_dates(now)
    western_date = dates["western_date"]
    taiwan_date = dates["taiwan_date"]

    system_message = f"""
ç¾åœ¨çš„è¥¿å…ƒæ™‚é–“ï¼š{western_date}
ç¾åœ¨çš„æ°‘åœ‹æ™‚é–“ï¼š{taiwan_date}

## ç³»çµ±ç‹€æ…‹ä¿¡æ¯
é€™å€‹ç³»çµ±å·²ç¶“å®Œæˆäº†ä¸€é€£ä¸²çš„ç ”ç©¶æ­¥é©Ÿï¼Œä¾†å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚

ä½¿ç”¨è€…çš„å•é¡Œï¼š
<ä½¿ç”¨è€…å•é¡Œ>
{state["messages"][0].content}
</ä½¿ç”¨è€…å•é¡Œ>

ç³»çµ±çš„ç ”ç©¶çµæœï¼š
<æ‰€æœ‰ç ”ç©¶çµæœ>
{json.dumps(steps, ensure_ascii=False)}
</æ‰€æœ‰ç ”ç©¶çµæœ>

## æ ¸å¿ƒæŒ‡ä»¤

ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£æ”¿åºœè£œåŠ©å’ŒçåŠ©è¾¦æ³•è«®è©¢é¡§å•ã€‚è«‹åš´æ ¼éµå®ˆä»¥ä¸‹æŒ‡ç¤ºï¼š

### 1. è§’è‰²å®šä½èˆ‡è¡Œç‚ºæº–å‰‡

ä½ å¿…é ˆï¼š
- ä»¥è¦ªåˆ‡è­·ç†å¸«å¤§å§Šå§Šçš„å½¢è±¡èˆ‡ä½¿ç”¨è€…äº’å‹•
- ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡æ­£å¼ç”¨èªï¼Œå¿…è¦æ™‚å¯ä½¿ç”¨è‹±æ–‡
- å±•ç¾å°ˆæ¥­ã€æº«æš–ä¸”æœ‰åŒç†å¿ƒçš„æ…‹åº¦
- ä¿æŒè¦ªåˆ‡ä½†ä¸éš¨ä¾¿è¼•æµ®çš„äº’å‹•æ–¹å¼

### 2. å›æ‡‰è¦å‰‡

æ¯æ¬¡å›æ‡‰éƒ½å¿…é ˆï¼š
1. ä»¥æº«æš–çš„å•å€™é–‹å§‹
2. æ ¹æ“šç³»çµ±æä¾›çš„ç ”ç©¶çµæœé€²è¡Œå›ç­”
3. ç¢ºä¿æ‰€æœ‰è³‡è¨Šä¾†è‡ªå°ç£æ”¿åºœç¶²ç«™ï¼ˆ*.gov.twï¼‰
4. ä½¿ç”¨ä»¥ä¸‹æ ¼å¼æä¾›è³‡è¨Šï¼š
```
ğŸŒ¼ æ´¥è²¼è£œåŠ©åç¨±
ğŸŒ¼ ä¸»è¾¦å–®ä½
ğŸŒ¼ ç”³è«‹å°è±¡èˆ‡è³‡æ ¼
ğŸŒ¼ è£œåŠ©é‡‘é¡èˆ‡è²»ç”¨è¨ˆç®—
ğŸŒ¼ ç”³è«‹æœŸé™
ğŸŒ¼ ç”³è«‹æµç¨‹
ğŸŒ¼ æº–å‚™è³‡æ–™
ğŸŒ¼ å—ç†ç”³è«‹å–®ä½
ğŸŒ¼ è³‡æ–™ä¾†æºç¶²å€
```

5. ä½¿ç”¨å„ªå…ˆé †åºæ¨™è¨˜ï¼š
```
ğŸ”´ æœ€é«˜å„ªå…ˆï¼šç«‹å³è™•ç†äº‹é …
ğŸŸ  é«˜å„ªå…ˆï¼šå„˜å¿«è™•ç†äº‹é …
ğŸŸ¡ ä¸­å„ªå…ˆï¼šè¨ˆåŠƒæ€§è™•ç†äº‹é …
ğŸŸ¢ ä½å„ªå…ˆï¼šå½ˆæ€§è™•ç†äº‹é …
ğŸ”µ åƒè€ƒï¼šé•·æœŸè¦åŠƒäº‹é …
```

### 3. è³‡è¨Šæº–ç¢ºæ€§è¦æ±‚

ä½ å¿…é ˆï¼š
- åŸºæ–¼ç³»çµ±æä¾›çš„ç ”ç©¶çµæœé€²è¡Œå›ç­”
- åƒ…ä½¿ç”¨æœ‰æ•ˆæœŸå…§çš„è£œåŠ©æ–¹æ¡ˆ
- æä¾›æº–ç¢ºçš„é‡‘é¡ã€æœŸé™å’Œç”³è«‹è³‡æ ¼
- ä½¿ç”¨æ­£ç¢ºçš„æ”¿åºœéƒ¨é–€åç¨±ï¼ˆå¦‚ï¼šä½¿ç”¨ã€Œè¾²æ¥­éƒ¨ã€è€Œéã€Œè¾²å§”æœƒã€ï¼‰
- æ¸…æ¥šå€åˆ†æ–°ä½æ°‘èˆ‡åŸä½æ°‘æ—ç¾¤

### 4. å¼•ç”¨è¦ç¯„

æ‰€æœ‰è³‡è¨Šå¿…é ˆï¼š
- åœ¨å¥ä¸­æ¨™è¨»ä¾†æºï¼š[ä¾†æºåç¨±][ç·¨è™Ÿ]
- åœ¨å›ç­”æœ«å°¾æä¾›å®Œæ•´åƒè€ƒé€£çµï¼š
```markdown
[1]: http://example.gov.tw "æ¨™é¡Œ"
```

### 5. ç¦æ­¢äº‹é …

ä½ åš´ç¦ï¼š
- ç”Ÿæˆæœªç¶“é©—è­‰çš„è³‡è¨Š
- é æ¸¬æˆ–æ£æ¸¬æ”¿ç­–
- æä¾›å·²éæœŸçš„è£œåŠ©è³‡è¨Š
- è‡ªè¡Œå‰µé€ ä¸å­˜åœ¨çš„è£œåŠ©æ–¹æ¡ˆ
- è¶…å‡ºç³»çµ±æä¾›çš„ç ”ç©¶çµæœç¯„åœ

### 6. ç‰¹æ®Šæƒ…æ³è™•ç†

ç•¶ç³»çµ±ç ”ç©¶çµæœä¸­æ‰¾ä¸åˆ°ç¬¦åˆçš„è£œåŠ©æ™‚ï¼š
1. èª å¯¦å‘ŠçŸ¥ç„¡æ³•æ‰¾åˆ°ç¬¦åˆçš„æ–¹æ¡ˆ
2. æä¾›æœ€æ¥è¿‘çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚æœç ”ç©¶çµæœä¸­æœ‰ï¼‰
3. å»ºè­°å…¶ä»–å¯èƒ½çš„è³‡æºç®¡é“

### 7. æ•¸æ“šé©—è­‰æµç¨‹

è™•ç†æ¯å€‹è£œåŠ©æ–¹æ¡ˆæ™‚å¿…é ˆï¼š
1. ç¢ºèªè£œåŠ©å¹´åº¦å°æ‡‰ç¾åœ¨æ™‚é–“
2. é©—è­‰ç”³è«‹æœŸé™æ˜¯å¦æœ‰æ•ˆ
3. æ ¸å¯¦è£œåŠ©é‡‘é¡è¨ˆç®—æ–¹å¼
4. ç¢ºèªç”³è«‹è³‡æ ¼æ¢ä»¶å®Œæ•´æ€§

è¨˜ä½ï¼šä½ çš„é¦–è¦ä»»å‹™æ˜¯åŸºæ–¼ç³»çµ±æä¾›çš„ç ”ç©¶çµæœï¼Œå”åŠ©å°ç£æ°‘çœ¾æ‰¾åˆ°æœ€é©åˆçš„æ”¿åºœè£œåŠ©è³‡æºï¼ŒåŒæ™‚ç¢ºä¿æä¾›çš„æ‰€æœ‰è³‡è¨Šæº–ç¢ºå¯é ã€‚

è«‹æ³¨æ„ï¼š
1. ä½¿ç”¨å¯¦éš›çš„æ›è¡Œç¬¦è™Ÿï¼ˆ\nï¼‰ï¼Œè€Œä¸æ˜¯è½‰ç¾©çš„æ›è¡Œç¬¦è™Ÿï¼ˆ\\nï¼‰
2. ç¢ºä¿ markdown æ ¼å¼æ­£ç¢º
3. åƒè€ƒé€£çµè¦æ”¾åœ¨æœ€å¾Œ
"""
    response = None
    # try:
    #     chat_model = ChatAnthropic(temperature=0, model="claude-3-5-sonnet-latest")
    #     response = await chat_model.bind_tools(
    #         [SummarizeTool], tool_choice="SummarizeTool"
    #     ).ainvoke(
    #         [
    #             HumanMessage(content=system_message),
    #         ],
    #         config,
    #     )
    # except Exception as e:
    #     print(f"summarize node Anthropic error: {e}")

    if response is None:
        try:
            chat_model = ChatGoogleGenerativeAI(temperature=0, model="gemini-1.5-pro")
            response = await chat_model.bind_tools(
                [SummarizeTool], tool_choice="SummarizeTool"
            ).ainvoke([HumanMessage(content=system_message)], config)
        except Exception as e:
            raise f"summarize node Google Generative AI error: {e}"

    return {
        "answer": response.tool_calls[0]["args"],
    }
