import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from textblob import TextBlob
from transformers import pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import numpy as np
from response import generate_response
from memory import ConversationMemory

nltk.download('punkt')
nltk.download('wordnet')

# Initialize NLP tools
lemmatizer = WordNetLemmatizer()
ner_pipeline = pipeline('ner', model='dbmdz/bert-large-cased-finetuned-conll03-english')

# Expanded and advanced intent data with emojis
intent_data = [
    ("Hello, how are you? ðŸ˜Š", "greeting"),
    ("Hey! ðŸ‘‹", "greeting"),
    ("Good morning! â˜€ï¸", "greeting"),
    ("Good night! ðŸŒ™", "farewell"),
    ("Bye, see you later! ðŸ‘‹", "farewell"),
    ("Can you help me with this project? ðŸ“", "assistance"),
    ("Iâ€™m stuck, can you guide me? ðŸ†˜", "assistance"),
    ("I need advice on something ðŸ’¡", "assistance"),
    ("Whatâ€™s the weather like today? ðŸŒ¦ï¸", "weather"),
    ("Is it going to rain tomorrow? â˜”", "weather"),
    ("How hot is it outside? ðŸ”¥", "weather"),
    ("Tell me a joke ðŸ˜‚", "entertainment"),
    ("Play some music ðŸŽ¶", "entertainment"),
    ("Recommend me a good movie ðŸŽ¥", "entertainment"),
    ("Suggest a TV show ðŸ“º", "entertainment"),
    ("I need to book a flight âœˆï¸", "booking"),
    ("Reserve a table at a restaurant ðŸ½ï¸", "booking"),
    ("Can you schedule a doctorâ€™s appointment? ðŸ¥", "booking"),
    ("Whatâ€™s the capital of France? ðŸ—ºï¸", "information"),
    ("How far is the moon? ðŸŒ•", "information"),
    ("Explain quantum physics to me ðŸ§ ", "information"),
    ("Iâ€™m feeling sad ðŸ˜¢", "emotional_support"),
    ("I need someone to talk to ðŸ’¬", "emotional_support"),
    ("Iâ€™m so excited today! ðŸŽ‰", "emotional_support"),
    ("I feel so lonely ðŸ˜”", "emotional_support"),
    ("I'm stressed about my exams ðŸ“š", "emotional_support"),
    ("Iâ€™m really anxious ðŸ˜Ÿ", "emotional_support"),
    ("I feel unmotivated ðŸ˜ž", "emotional_support"),
    ("I need a confidence boost ðŸ’ª", "emotional_support"),
]

# Preparing data
texts, labels = zip(*intent_data)
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)
y = np.array(labels)

# Splitting data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training intent classifier
classifier = SVC(kernel='linear', probability=True)
classifier.fit(X_train, y_train)

# Evaluating classifier
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))

# Advanced intent detection
def detect_intent(text):
    X_input = vectorizer.transform([text])
    return classifier.predict(X_input)[0]

# Text preprocessing
def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]
    return lemmatized

# Sentiment analysis
def analyze_sentiment(text):
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    if sentiment > 0:
        return 'positive'
    elif sentiment < 0:
        return 'negative'
    else:
        return 'neutral'

# Named Entity Recognition (NER)
def extract_entities(text):
    entities = ner_pipeline(text)
    return {entity['word']: entity['entity'] for entity in entities}

# Initialize memory
memory = ConversationMemory()

if __name__ == "__main__":
    sample_text = "Hey there! I need some help with my project. Can you guide me?"
    intent = detect_intent(sample_text)
    sentiment = analyze_sentiment(sample_text)
    entities = extract_entities(sample_text)
    response = generate_response(intent, memory.get_emotion(), memory.get_context(), sentiment, entities)
    memory.add_to_memory(sample_text, response, intent)
    adapted_response = memory.adapt_response(response)
    print("Session Memory:", memory.get_context())
    print("Current Emotion State:", memory.get_emotion())
    print("Extracted Entities:", entities)
    print("Sentiment:", sentiment)
    print("Adapted Response:", adapted_response)
