Metadata-Version: 2.4
Name: openai-mcp-server
Version: 1.0.0
Summary: Dockerized MCP server for OpenAI models
Requires-Python: >=3.13
Requires-Dist: mcp>=1.6.0
Description-Content-Type: text/markdown

# openai_mcp_server MCP server

Dockerized MCP server for OpenAI models

## Components

### Resources

The server implements a simple note storage system with:
- Custom note:// URI scheme for accessing individual notes
- Each note resource has a name, description and text/plain mimetype

### Prompts

The server provides a single prompt:
- summarize-notes: Creates summaries of all stored notes
  - Optional "style" argument to control detail level (brief/detailed)
  - Generates prompt combining all current notes with style preference

### Tools

The server implements one tool:
- add-note: Adds a new note to the server
  - Takes "name" and "content" as required string arguments
  - Updates server state and notifies clients of resource changes

## Configuration

[TODO: Add configuration details specific to your implementation]

## Quickstart

### Install

#### Claude Desktop

On MacOS: `~/Library/Application\ Support/Claude/claude_desktop_config.json`
On Windows: `%APPDATA%/Claude/claude_desktop_config.json`

<details>
  <summary>Development/Unpublished Servers Configuration</summary>
  ```
  "mcpServers": {
    "openai_mcp_server": {
      "command": "uv",
      "args": [
        "--directory",
        "Z:\FUCK",
        "run",
        "openai_mcp_server"
      ]
    }
  }
  ```
</details>

<details>
  <summary>Published Servers Configuration</summary>
  ```
  "mcpServers": {
    "openai_mcp_server": {
      "command": "uvx",
      "args": [
        "openai_mcp_server"
      ]
    }
  }
  ```
</details>

## Development

### Building and Publishing

To prepare the package for distribution:

1. Sync dependencies and update lockfile:
```bash
uv sync
```

2. Build package distributions:
```bash
uv build
```

This will create source and wheel distributions in the `dist/` directory.

3. Publish to PyPI:
```bash
uv publish
```

Note: You'll need to set PyPI credentials via environment variables or command flags:
- Token: `--token` or `UV_PUBLISH_TOKEN`
- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`

### Debugging

Since MCP servers run over stdio, debugging can be challenging. For the best debugging
experience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).

You can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:

```bash
npx @modelcontextprotocol/inspector uv --directory Z:\FUCK run openai-mcp-server
```

Upon launching, the Inspector will display a URL that you can access in your browser to begin debugging.

## Building the Docker Image
```bash
docker build -t openai-mcp-server .
```

## Running the Docker Container
```bash
docker run -d -p 8000:8000 -e OPENAI_API_KEY=your_api_key_here openai-mcp-server
```

Replace `your_api_key_here` with your actual OpenAI API key.